{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8364e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#######################################################\n",
    "############    COPYRIGHT - DATA SOCIETY   ############\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "## NEURALNETWORKSANDDEEPLEARNING/TUNINGNEURALNETWORKS/NEURALNETWORKSANDDEEPLEARNING TUNINGNEURALNETWORKS 1 ##\n",
    "\n",
    "## NOTE: To run individual pieces of code, select the line of code and\n",
    "##       press ctrl + enter for PCs or command + enter for Macs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d161d8d6-d7a5-498c-ba3e-ed553b89b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 3: Loading packages  ####\n",
    "\n",
    "# Helper packages.\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Scikit-learn packages.\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# TensorFlow and supporting packages.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31c5e2ca-cfc4-447f-80b5-751e3b9e2f02",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ParamSpec' from 'typing_extensions' (/usr/local/Caskroom/mambaforge/base/envs/tf/lib/python3.9/site-packages/typing_extensions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mneptune\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnew\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mneptune\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/tf/lib/python3.9/site-packages/neptune/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2022, Neptune Labs Sp. z o.o.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneptune\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply_patches\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneptune\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     ANONYMOUS,\n\u001b[1;32m     20\u001b[0m     ANONYMOUS_API_TOKEN,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     stop,\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneptune\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/tf/lib/python3.9/site-packages/neptune/common/patches/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2022, Neptune Labs Sp. z o.o.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     16\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply_patches\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneptune\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbravado\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m patch \u001b[38;5;28;01mas\u001b[39;00m bravado_patch\n\u001b[1;32m     20\u001b[0m patches \u001b[38;5;241m=\u001b[39m [bravado_patch]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Apply patches when importing a patching module\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Should be called before usages of patched objects\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/tf/lib/python3.9/site-packages/neptune/common/patches/bravado.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbravado_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbravado_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     _bless_models,\n\u001b[1;32m     22\u001b[0m     _collect_models,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     _tag_models,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_post_processing\u001b[39m(spec):\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/tf/lib/python3.9/site-packages/bravado_core/model.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m iteritems\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m string_types\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mswagger_spec_validator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mref_validators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attach_scope\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbravado_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collapsed_properties\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbravado_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_dict_like\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/tf/lib/python3.9/site-packages/swagger_spec_validator/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mswagger_spec_validator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SwaggerValidationError\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mswagger_spec_validator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_spec_url\n\u001b[1;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSwaggerValidationError\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate_spec_url\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m ]\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/tf/lib/python3.9/site-packages/swagger_spec_validator/common.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpkg_resources\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resource_filename\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParamSpec\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CSafeLoader \u001b[38;5;28;01mas\u001b[39;00m SafeLoader\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ParamSpec' from 'typing_extensions' (/usr/local/Caskroom/mambaforge/base/envs/tf/lib/python3.9/site-packages/typing_extensions.py)"
     ]
    }
   ],
   "source": [
    "import neptune.new as neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbab702-b2f7-442a-8f19-520063f6643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune.new.integrations.tensorflow_keras import NeptuneCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eaf6895-1750-4cbe-830b-ca28272a035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting type_extensions\n",
      "  Downloading type_extensions-0.1.2-py2.py3-none-any.whl (5.6 kB)\n",
      "Installing collected packages: type_extensions\n",
      "Successfully installed type_extensions-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade type_extensions\n",
    "# %conda install -yc conda-forge typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 6: Setting up project parameters for Neptune  ####\n",
    "\n",
    "# Initialize your Neptune client.\n",
    "run = neptune.init(project='USER_NAME/PROJECT_NAME', #<- track your project\n",
    "                   api_token = 'API_TOKEN')          #<- set your API token\n",
    "             \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dfc0c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/matskarz/Skillsoft-Content/IntrotoNeural_Networks\n",
      "/Users/matskarz/Skillsoft-Content/IntrotoNeural_Networks/data\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 7: Directory settings  ####\n",
    "\n",
    "from pathlib import Path \n",
    "home_dir = Path(\".\").resolve()\n",
    "main_dir = home_dir.parent\n",
    "print(main_dir)\n",
    "data_dir = str(main_dir) + \"/data\"\n",
    "print(data_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc8bbc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
      "1   2     120000    2          2         2   26     -1      2      0      0   \n",
      "2   3      90000    2          2         2   34      0      0      0      0   \n",
      "3   4      50000    2          2         1   37      0      0      0      0   \n",
      "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...          0          0          0         0       689         0   \n",
      "1  ...       3272       3455       3261         0      1000      1000   \n",
      "2  ...      14331      14948      15549      1518      1500      1000   \n",
      "3  ...      28314      28959      29547      2000      2019      1200   \n",
      "4  ...      20940      19146      19131      2000     36681     10000   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default_payment_next_month  \n",
      "0         0         0         0                           1  \n",
      "1      1000         0      2000                           1  \n",
      "2      1000      1000      5000                           0  \n",
      "3      1100      1069      1000                           0  \n",
      "4      9000       689       679                           0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 8: Load the data  ####\n",
    "\n",
    "credit_card = pd.read_csv(str(data_dir) + '/credit_card_data.csv')\n",
    "print(credit_card.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35e86505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 10: Data prep: convenience function - cont'd  ####\n",
    "\n",
    "def data_prep(df):\n",
    "    \n",
    "    # Fill missing values with mean \n",
    "    df = df.fillna(df.mean()['BILL_AMT1'])\n",
    "\n",
    "    # Drop an unnecessary identifier column.\n",
    "    df = df.drop('ID',axis = 1)\n",
    "\n",
    "    # Convert 'sex' into dummy variables.\n",
    "    sex = pd.get_dummies(df['SEX'], prefix = 'sex', drop_first = True)\n",
    "    # Convert 'education' into dummy variables.\n",
    "    education = pd.get_dummies(df['EDUCATION'], prefix = 'education', drop_first = True)\n",
    "    # Convert 'marriage' into dummy variables.\n",
    "    marriage = pd.get_dummies(df['MARRIAGE'], prefix = 'marriage', drop_first = True)\n",
    "\n",
    "    # Drop `sex`, `education`, `marriage` from the data.\n",
    "    df.drop(['SEX', 'EDUCATION', 'MARRIAGE'], axis = 1, inplace = True)\n",
    "\n",
    "    # Concatenate `sex`, `education`, `marriage` dummies to our dataset.\n",
    "    df = pd.concat([df, sex, education, marriage], axis=1)\n",
    "    \n",
    "    # Separate predictors from data.\n",
    "    X = df.drop(['default_payment_next_month'], axis=1)\n",
    "\n",
    "    # Separate target from data.\n",
    "    y = df['default_payment_next_month']\n",
    "\n",
    "    # Set the seed to 1.\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # Split data into train, test, and validation set, use a 70 - 15 - 15 split.\n",
    "    # First split data into train-test with 70% for train and 30% for test.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.values,\n",
    "                                                        y,\n",
    "                                                        test_size = .3,\n",
    "                                                        random_state = 1)\n",
    "    \n",
    "    # Then split the test data into two halves: test and validation. \n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test,\n",
    "                                                    y_test,\n",
    "                                                    test_size = .5,\n",
    "                                                    random_state = 1)\n",
    "                                                    \n",
    "    print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape, \"Val shape:\", X_val.shape)\n",
    "    \n",
    "    # Transforms features by scaling each feature to a given range.\n",
    "    # The default is the range between 0 and 1.\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = min_max_scaler.transform(X_test)\n",
    "    X_val_scaled = min_max_scaler.transform(X_val)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, X_val_scaled, y_train, y_test, y_val\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b816e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (21000, 30) Test shape: (4500, 30) Val shape: (4500, 30)\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 11: Data prep  ####\n",
    "\n",
    "X_train_scaled, X_test_scaled, X_val_scaled, y_train, y_test, y_val = data_prep(credit_card)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eb1d1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 12:47:45.430825: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 12: Define metrics  ####\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc')\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e57344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 13: Define model function  ####\n",
    "\n",
    "def create_model(lr = .75):\n",
    "  # Let's set the seed so that we can reproduce the results.\n",
    "  tf.random.set_seed(1)\n",
    "  opt = Adam(learning_rate = lr) # <- set optimizer\n",
    "\n",
    "  model = Sequential([\n",
    "          Dense(32, activation='relu', \n",
    "                  input_dim=X_train_scaled.shape[1]),#<- set input and 1st hidden layer\n",
    "          Dense(32, activation='relu'),              #<- set 2nd hidden layer\n",
    "          Dense(1, activation='sigmoid')             #<- set output layer\n",
    "\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer = opt,            #<- set optimizer\n",
    "                loss='binary_crossentropy', #<- set loss function to binary_crossentropy\n",
    "                metrics= METRICS)           #<- set performance metric\n",
    "  return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 14: Launching Neptune: create callback  ####\n",
    "\n",
    "neptune_cbk = NeptuneCallback(run=run)\n",
    "callbacks = [neptune_cbk]\n",
    "\n",
    "# Create and compile the model.\n",
    "model = create_model()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1714c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 15: Fitting the model with Neptune callback  ####\n",
    "\n",
    "# Fit the model with NeptuneCallback\n",
    "model_default = model.fit(X_train_scaled, y_train,\n",
    "                          validation_data = (X_val_scaled, y_val),\n",
    "                          epochs = 25,\n",
    "                          verbose = 0,          #<- silence the epoch output in console (optional)\n",
    "                          callbacks = callbacks)#<- add callbacks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3972261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 21: Evaluate the model  ####\n",
    "\n",
    "model.evaluate(X_test_scaled, y_test)\n",
    "run.stop()\n",
    "\n",
    "\n",
    "#######################################################\n",
    "####  CONGRATULATIONS ON COMPLETING THIS MODULE!   ####\n",
    "#######################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ccae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#######################################################\n",
    "############    COPYRIGHT - DATA SOCIETY   ############\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "## NEURALNETWORKSANDDEEPLEARNING/TUNINGNEURALNETWORKS/NEURALNETWORKSANDDEEPLEARNING TUNINGNEURALNETWORKS 2 ##\n",
    "\n",
    "## NOTE: To run individual pieces of code, select the line of code and\n",
    "##       press ctrl + enter for PCs or command + enter for Macs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ba8968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 4: Define the tuner (cont'd)  ####\n",
    "\n",
    "def tune_model(hp):\n",
    "\n",
    "    # Number of 1st hidden layer neurons.\n",
    "    units = hp.Int('units',        #<- Number of neurons\n",
    "                   min_value = 8,  #<- min value\n",
    "                   max_value = 64, #<- max value\n",
    "                   step = 8)\n",
    "    \n",
    "    # Tuning activation function for 1st hidden layer.\n",
    "    activation = hp.Choice('activation', #<- Activation function\n",
    "                             [             #<- Types of activation functions\n",
    "                                 'relu',\n",
    "                                 'tanh',\n",
    "                                 'sigmoid'\n",
    "                             ])\n",
    "    \n",
    "    dropout_1 = hp.Float('dropout_1',\n",
    "                         min_value = 0.0,\n",
    "                         max_value = 0.5,\n",
    "                         default = 0.25,\n",
    "                         step = 0.05)\n",
    "    \n",
    "    # Tuning optimizer.\n",
    "    optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
    "    \n",
    "    # Tuning learning rate\n",
    "    lr = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(\n",
    "            units=units,\n",
    "            activation=activation,\n",
    "            input_dim=X_train_scaled.shape[1],\n",
    "        ),\n",
    "        keras.layers.Dense(units=units, activation=activation),\n",
    "        Dropout(rate=dropout_1),\n",
    "        keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    \n",
    "    # Compile model.\n",
    "    model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = METRICS)\n",
    "    \n",
    "    return model\n",
    "MAX_TRIALS = 10\n",
    "EXECUTIONS_PER_TRIAL = 5\n",
    "tuner = RandomSearch(\n",
    "    tune_model,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = MAX_TRIALS,\n",
    "    executions_per_trial = EXECUTIONS_PER_TRIAL,\n",
    "    directory = 'final_tuned_model',\n",
    "    project_name = 'final_tuned_model',\n",
    "    seed = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa340402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 64, 'step': 8, 'sampling': None}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
      "dropout_1 (Float)\n",
      "{'default': 0.25, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.05, 'sampling': None}\n",
      "optimizer (Choice)\n",
      "{'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd', 'rmsprop'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 5: View search space summary  ####\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d8198a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 12:48:40.677378: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 6: Fit the model  ####\n",
    "\n",
    "tuner.search(x=X_train_scaled,\n",
    "             y=y_train,\n",
    "             verbose=0,\n",
    "             epochs=25,\n",
    "             validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84272fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': 56,\n",
       " 'activation': 'tanh',\n",
       " 'dropout_1': 0.25,\n",
       " 'optimizer': 'adam',\n",
       " 'learning_rate': 0.001}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 7: View the optimal parameters  ####\n",
    "\n",
    "optimal_params = tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values\n",
    "optimal_params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11e83e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 8: Define and compile optimized model  ####\n",
    "\n",
    "def create_optimized_model(units, activation, dropout_1, optimizer, learning_rate, dropout_seed = 1):\n",
    "\n",
    "    # Set up model.\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(units,\n",
    "                    input_dim = X_train_scaled.shape[1],\n",
    "                    activation = activation))\n",
    "    model.add(Dense(units,\n",
    "                    activation = activation))\n",
    "    \n",
    "    if dropout_1 is not None:\n",
    "        model.add(Dropout(rate = dropout_1, seed = dropout_seed))\n",
    "        model.add(Dense(1, activation = 'sigmoid'))\n",
    "    # Compile model.\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = METRICS)\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d024829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 9: Setup Neptune run for optimized model  ####\n",
    "\n",
    "# Initialize your Neptune client.\n",
    "run = neptune.init(project='USER_NAME/PROJECT_NAME', #<- track your project\n",
    "                   api_token = 'API_TOKEN')          #<- set your API token\n",
    "             \n",
    "neptune_cbk = NeptuneCallback(run=run)\n",
    "callbacks = [neptune_cbk]\n",
    "# Create and compile the optimized model.\n",
    "tb_model = create_optimized_model(**optimal_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2559ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 10: Fit the optimized model  ####\n",
    "\n",
    "tb_model.fit(X_train_scaled,\n",
    "             y_train,\n",
    "             validation_data = (X_val_scaled, y_val),\n",
    "             epochs = 25,\n",
    "             verbose = 0,          #<- silence the epoch output in console (optional)\n",
    "             callbacks = callbacks)#<- add callbacks\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c90f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 11: Evaluate optimized model on test data  ####\n",
    "\n",
    "tb_model.evaluate(X_test_scaled, y_test)\n",
    "run.stop()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da210449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 25: Exercise   ####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################################\n",
    "####  CONGRATULATIONS ON COMPLETING THIS MODULE!   ####\n",
    "#######################################################\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
